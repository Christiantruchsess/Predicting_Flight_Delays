{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_taxi_Ndays_rolling(df, days):\n",
    "    \"\"\"\n",
    "    This function calculates and adds additional columns for rolling average taxi_in/taxi_out time per airport per day.\n",
    "    \n",
    "    Args:\n",
    "        df - df to process as DataFrame\n",
    "        days - Days to calculate rolling number for taxi_in, taxi_out time\n",
    "    Output:\n",
    "        processed DataFrame is returned back\n",
    "    \"\"\"\n",
    "    cols={'origin':['origin_airport_id', 'taxi_out'],\n",
    "             'destination':['dest_airport_id','taxi_in']}\n",
    "    \n",
    "    df = df.sort_values(['fl_date']) #Sorting by fl_date just in case it was not sorted before. \n",
    "                                        #It is important for rolling average\n",
    "    \n",
    "    #Iterating the keys in cols which has columns we interested in.\n",
    "    for key in cols.keys():\n",
    "        \n",
    "        #First we calculate average taxi time per airport per day\n",
    "        df_taxi=df[[cols[key][0], 'fl_date',  cols[key][1]]].groupby([cols[key][0], 'fl_date']).mean().reset_index()\n",
    "\n",
    "        #Based on our average taxi time we can calculate rolling average\n",
    "        df_taxi_roll=df_taxi.groupby([cols[key][0]]).rolling(days, on='fl_date'\n",
    "                                                                           ).agg({cols[key][1]:'mean'}).reset_index()\n",
    "        #Renaming column to avoid collision during merging\n",
    "        df_taxi_roll.rename(columns={cols[key][1]: str(days) +'d ' + cols[key][1]}, inplace=True)\n",
    "        \n",
    "        #Merging with initial DataFrame\n",
    "        df=df.merge(df_taxi_roll, on=[cols[key][0], 'fl_date' ] , how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_traffic_rolling(df, days):\n",
    "    \"\"\"\n",
    "    This function calculates and adds additional column for rolling average number of flights per airport per day.\n",
    "    \n",
    "    Args:\n",
    "        df - DataFrame to process.\n",
    "        days - Days as integer to calculate rolling average\n",
    "        \n",
    "    Output:\n",
    "        dataframe - initial dataframe with additional column\n",
    "    \"\"\"\n",
    "    cols = ['origin_airport_id', 'dest_airport_id']\n",
    "    \n",
    "    df = df.sort_values(['fl_date']) #Sorting by fl_date just in case it was not sorted before. \n",
    "                                        #It is important for rolling average\n",
    "    for item in cols:\n",
    "        #Now calculating trafic per airport per day. Also will calculate N - days rolling average.\n",
    "        count_flight=df[[item, 'fl_date', 'mkt_carrier']].groupby([item, 'fl_date'\n",
    "                                                                             ]).count().reset_index()\n",
    "        \n",
    "        count_flights_roll= count_flight.groupby([item]).rolling(days, on='fl_date'\n",
    "                                                                       ).agg({'mkt_carrier':'mean'}).reset_index()\n",
    "        #Renaming to avoid collision during merging\n",
    "        count_flights_roll.rename(columns={'mkt_carrier': str(days) + 'd roll flts ' + item}, inplace=True)\n",
    "        \n",
    "        #Merging\n",
    "        df=df.merge(count_flights_roll, on=[item, 'fl_date' ] , how='left')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_outlier_limits(df,column):\n",
    "    \"\"\"\n",
    "    Function calculates Interquartile Range (IQR) in order to return upper and lower limits after which to consider a value an outlier. \n",
    "        A limit is defined as 1.5 times the IQR below Quartile 1 (Q1) or above Quartile 3 (Q3).\n",
    "    \n",
    "    Args:\n",
    "        df - Pandas DataFrame \n",
    "        column - Column of DataFrame with the aforementioned outliers, input as a string.\n",
    "    Output:\n",
    "        Processed DataFrame is returned (subset of original).\n",
    "    \"\"\"\n",
    "    \n",
    "    # The .describe() method for Pandas DataFrames outputs a Pandas Series; index number 4 corresponds to \n",
    "    # Quartile 1, index number 6 to Quartile 3. The Inter-Quartile Range (IQR) is then calculated as Q3 - Q1.\n",
    "    Q1 = df[column].describe()[4]\n",
    "    Q3 = df[column].describe()[6]\n",
    "    IQR = float(Q3 - Q1)\n",
    "    \n",
    "    # An outlier threshold is calculated as 1.5 times the IQR. \n",
    "    outlier_threshold = 1.5 * IQR\n",
    "    lower_limit = Q1 - outlier_threshold\n",
    "    upper_limit = Q3 + outlier_threshold\n",
    "    \n",
    "    limits = [lower_limit, upper_limit]\n",
    "   \n",
    "    return limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column):\n",
    "    \"\"\"\n",
    "    Function removes rows with outliers from a dataframe, as defined by the return_outlier_limits function. \n",
    "    \n",
    "    Args:\n",
    "        df - Pandas DataFrame \n",
    "        column - Column of DataFrame with the aforementioned outliers, input as a string.\n",
    "    Output:\n",
    "        Processed DataFrame is returned (subset of original).\n",
    "    \"\"\"\n",
    "   \n",
    "    # Call return_outlier_limits function to return list `limit` with two values, lower and upper: limit[0] corresponds to the lower limit, \n",
    "    # limit[1] to the upper limit. \n",
    "    limits = return_outlier_limits(df,column)\n",
    "    \n",
    "    # Use boolean operators to define subset of column values that exclude outliers\n",
    "    df_no_outliers = df[(df[column] > limits[0]) & (df[column] < limits[1])]\n",
    "    \n",
    "    return df_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_with_mean(df,column,include_outliers=False):\n",
    "    \"\"\"\n",
    "    This function replaces all NaN values for a given column in a dataframe with the mean of the column values.\n",
    "   \n",
    "    Args:\n",
    "        df - Pandas DataFrame \n",
    "        column - Column of DataFrame, input as a string.\n",
    "        include_outliers - If True, calculates mean of all values,\n",
    "            if False, does not consider outliers when calculating mean. Defaults to False.\n",
    "    Output:\n",
    "        Processed DataFrame is returned.\n",
    "    \"\"\"\n",
    "    if include_outliers == False:\n",
    "        df_no_outliers = remove_outliers(df,column)\n",
    "        mean = df_no_outliers[column].mean()\n",
    "    else:\n",
    "        mean = df[column].mean()\n",
    "        \n",
    "    # Replace NaN values with previously calculated mean, using .fillna() Pandas method.\n",
    "    df[column].fillna(mean,inplace=True)\n",
    "   \n",
    "    # Return processed DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dates_ordinal(df, dates_column):\n",
    "    \"\"\"\n",
    "    This function converts the dates of a DataFrame column to integers, in order to easily fit the data to a regression model. \n",
    "    \n",
    "    More specifically, the function toordinal() returns the proleptic Gregorian ordinal of a date.\n",
    "    \n",
    "    In simple terms datetime.toordinal() returns the day count from the date 01/01/01\n",
    "    \n",
    "    Though Gregorian calendar was not followed before October 1582, several computer\n",
    "        systems follow the Gregorian calendar for the dates that comes even before October 1582.\n",
    "        Python's date class also does the same.\n",
    "    \n",
    "    Args:\n",
    "        df - Pandas DataFrame \n",
    "        dates_column - column of DataFrame, input as a string. All values in column must be \n",
    "            of type datetime64[ns].\n",
    "    Output:\n",
    "        Processed DataFrame is returned.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The function imports the required datetime module.\n",
    "    import datetime as dt\n",
    "    \n",
    "    # Applies datetime.toordinal() function to desired column of DataFrame.\n",
    "    df[dates_column] = df[dates_column].map(dt.datetime.toordinal)\n",
    "    \n",
    "    # Returns processed DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_features(df, desired_features = ['fl_date','mkt_carrier_fl_num','origin_airport_id','dest_airport_id','crs_dep_time',\n",
    "                                             'crs_arr_time','crs_elapsed_time','distance','arr_delay']):\n",
    "    df = df[desired_features]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_month_dummies(df, date_column):\n",
    "    \"\"\"\n",
    "    This function adds dummy variable columns for months.\n",
    "    \n",
    "    Args:\n",
    "        df - Dataframe which needed to be processed.\n",
    "        date_column as string. Column with dates\n",
    "    Output:\n",
    "        Dataframe with dummy varialbles.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['month']=df[date_column].dt.month\n",
    "    df = pd.get_dummies(df, columns=['month'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_weather_flights(df_flights, df_weather):\n",
    "    \"\"\"\n",
    "    This function merges weather data information to flights table based on three columns - \n",
    "    'fl_date', 'origin_city_name', 'dest_city_name'.\n",
    "    \n",
    "    For each row in flights table additional columns will be added (for origin city and dest city) -\n",
    "        'wspd' - wind speed\n",
    "        'visibility'  - visibility\n",
    "        'conditions'  - weather conditions, which is categorical variable and will be converted to the dummy variables.\n",
    "    Args:\n",
    "        df_flights - dataframe with flights data.\n",
    "        df_weather - dataframe with weather data.\n",
    "    Output:\n",
    "        df_flights - processed flights dataframe with additional columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Dropping 'weather_type' column.\n",
    "    try:\n",
    "        df_weather.drop(columns=['weathertype'], inplace=True)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "    #Preparing columns for origin city.\n",
    "    df_weather_origin = df_weather.rename(columns={'city_name':'origin_city_name',\n",
    "                              'wspd':'origin_city_wspd',\n",
    "                                'visibility':'origin_visibility',\n",
    "                                'conditions':'origin_cond'})\n",
    "    \n",
    "    #Merging origin city weather to the flights dataframe. Left join is used.\n",
    "    df_flights = df_flights.merge(df_weather_origin, on=['fl_date', 'origin_city_name'], how='left')\n",
    "    \n",
    "    #Preparing columns for dest city.\n",
    "    df_weather_dest = df_weather.rename(columns={'city_name':'dest_city_name',\n",
    "                              'wspd':'dest_city_wspd',\n",
    "                                'visibility':'dest_visibility',\n",
    "                                'conditions':'dest_cond'})\n",
    "    \n",
    "    #Merging destination city weather to the flights dataframe. Left join is used.\n",
    "    df_flights = df_flights.merge(df_weather_dest, on=['fl_date', 'dest_city_name'], how='left')\n",
    "    \n",
    "    #Making dummy variables out of categorical ones:'origin_cond', 'dest_cond'\n",
    "    df_flights = pd.get_dummies(df_flights, columns=['origin_cond', 'dest_cond'])\n",
    "    \n",
    "    #list of different categories. There are some categories which consists of two ones like \"Snow, Overcast\" 'Rain, Partially cloudy' \n",
    "    #The aim is to get rid of them from the dataframe\n",
    "    list_categories=df_weather['conditions'].unique()\n",
    "    \n",
    "    #City prefix\n",
    "    columns=['origin_cond', 'dest_cond']\n",
    "    \n",
    "    for cond in list_categories:\n",
    "        #Need to find those with comma in the name\n",
    "        if type(cond) == type('some string') and cond.find(',')>-1:\n",
    "            #comma found\n",
    "            lst= cond.split(', ')\n",
    "            for city_cond in columns:\n",
    "                if city_cond + '_' + cond in df_flights.columns:\n",
    "                    df_flights.loc[df_flights[city_cond + '_' + cond]==1, city_cond + '_' + lst[0]]=1 #Updated respective column\n",
    "                    df_flights.loc[df_flights[city_cond + '_' + cond]==1, city_cond + '_' + lst[1]]=1 #Updated respective column\n",
    "                    df_flights.drop(columns=[city_cond + '_' + cond], inplace=True) #Dropping the column\n",
    "                \n",
    "    return df_flights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
