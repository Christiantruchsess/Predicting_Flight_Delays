{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_taxi_Ndays_rolling(df, days):\n",
    "    \"\"\"\n",
    "    This function calculates and adds additional columns for rolling average taxi_in/taxi_out time per airport per day.\n",
    "    \n",
    "    Args:\n",
    "        df - df to process as DataFrame\n",
    "        days - Days to calculate rolling number for taxi_in, taxi_out time\n",
    "    Output:\n",
    "        processed DataFrame is returned back\n",
    "    \"\"\"\n",
    "    cols={'origin':['origin_airport_id', 'taxi_out'],\n",
    "             'destination':['dest_airport_id','taxi_in']}\n",
    "    \n",
    "    df = df.sort_values(['fl_date']) #Sorting by fl_date just in case it was not sorted before. \n",
    "                                        #It is important for rolling average\n",
    "    \n",
    "    #Iterating the keys in cols which has columns we interested in.\n",
    "    for key in cols.keys():\n",
    "        \n",
    "        #First we calculate average taxi time per airport per day\n",
    "        df_taxi=df[[cols[key][0], 'fl_date',  cols[key][1]]].groupby([cols[key][0], 'fl_date']).mean().reset_index()\n",
    "\n",
    "        #Based on our average taxi time we can calculate rolling average\n",
    "        df_taxi_roll=df_taxi.groupby([cols[key][0]]).rolling(days, on='fl_date'\n",
    "                                                                           ).agg({cols[key][1]:'mean'}).reset_index()\n",
    "        #Renaming column to avoid collision during merging\n",
    "        df_taxi_roll.rename(columns={cols[key][1]: str(days) +'d ' + cols[key][1]}, inplace=True)\n",
    "        \n",
    "        #Merging with initial DataFrame\n",
    "        df=df.merge(df_taxi_roll, on=[cols[key][0], 'fl_date' ] , how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_traffic_rolling(df, days):\n",
    "    \"\"\"\n",
    "    This function calculates and adds additional column for rolling average number of flights per airport per day.\n",
    "    \n",
    "    Args:\n",
    "        df - DataFrame to process.\n",
    "        days - Days as integer to calculate rolling average\n",
    "        \n",
    "    Output:\n",
    "        dataframe - initial dataframe with additional column\n",
    "    \"\"\"\n",
    "    cols = ['origin_airport_id', 'dest_airport_id']\n",
    "    \n",
    "    df = df.sort_values(['fl_date']) #Sorting by fl_date just in case it was not sorted before. \n",
    "                                        #It is important for rolling average\n",
    "    for item in cols:\n",
    "        #Now calculating trafic per airport per day. Also will calculate N - days rolling average.\n",
    "        count_flight=df[[item, 'fl_date', 'mkt_carrier']].groupby([item, 'fl_date'\n",
    "                                                                             ]).count().reset_index()\n",
    "        \n",
    "        count_flights_roll= count_flight.groupby([item]).rolling(days, on='fl_date'\n",
    "                                                                       ).agg({'mkt_carrier':'mean'}).reset_index()\n",
    "        #Renaming to avoid collision during merging\n",
    "        count_flights_roll.rename(columns={'mkt_carrier': str(days) + 'd roll flts ' + item}, inplace=True)\n",
    "        \n",
    "        #Merging\n",
    "        df=df.merge(count_flights_roll, on=[item, 'fl_date' ] , how='left')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_with_mean(df,column):\n",
    "    \"\"\"\n",
    "    This function replaces all NaN values for a given column in a dataframe with the mean of the column values,\n",
    "        _without_ taking outliers into consideration when calculating said mean.\n",
    "    Args:\n",
    "        df - Pandas DataFrame \n",
    "        column - column of DataFrame, input as a string. \n",
    "    Output:\n",
    "        Processed DataFrame is returned.\n",
    "    \"\"\"\n",
    "    # The .describe() method for Pandas DataFrames outputs a Pandas Series; index number 4 corresponds to \n",
    "    # Quartile 1, index number 6 to Quartile 3. The Inter-Quartile Range (IQR) is then calculated as Q3 - Q1.\n",
    "    Q1 = df[column].describe()[4]\n",
    "    Q3 = df[column].describe()[6]\n",
    "    IQR = float(Q3 - Q1)\n",
    "    # An outlier threshold is calculated as 1.5 times the IQR. Any value that is below Q1 minus the threshold,\n",
    "    # or above Q3 plus the threshold, is considered an outlier. \n",
    "    outlier_threshold = 1.5 * IQR\n",
    "    lower_limit = Q1 - outlier_threshold\n",
    "    upper_limit = Q3 + outlier_threshold\n",
    "    \n",
    "    # Use boolean operators to define subset of column values that exclude outliers\n",
    "    subset_without_outliers = df[(df[column] > lower_limit) & (df[column] < upper_limit)][column]\n",
    "    \n",
    "    # Calculate the mean for said subset. \n",
    "    mean_without_outliers = subset_without_outliers.mean()\n",
    "    \n",
    "    # Replace NaN values with previously calculated mean, using .fillna() Pandas method.\n",
    "    df[column].fillna(mean_without_outliers,inplace=True)\n",
    "    \n",
    "    # Return processed DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dates_ordinal(df, dates_column):\n",
    "    \"\"\"\n",
    "    This function converts the dates of a DataFrame column to integers, in order to easily fit the data to a regression model. \n",
    "    \n",
    "    More specifically, the function toordinal() returns the proleptic Gregorian ordinal of a date.\n",
    "    \n",
    "    In simple terms datetime.toordinal() returns the day count from the date 01/01/01\n",
    "    \n",
    "    Though Gregorian calendar was not followed before October 1582, several computer\n",
    "        systems follow the Gregorian calendar for the dates that comes even before October 1582.\n",
    "        Python's date class also does the same.\n",
    "    \n",
    "    Args:\n",
    "        df - Pandas DataFrame \n",
    "        dates_column - column of DataFrame, input as a string. All values in column must be \n",
    "            of type datetime64[ns].\n",
    "    Output:\n",
    "        Processed DataFrame is returned.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The function imports the required datetime module.\n",
    "    import datetime as dt\n",
    "    \n",
    "    # Applies datetime.toordinal() function to desired column of DataFrame.\n",
    "    df[dates_column] = df[dates_column].map(dt.datetime.toordinal)\n",
    "    \n",
    "    # Returns processed DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_features(df, full_features = ['fl_date','mkt_unique_carrier','branded_code_share','mkt_carrier','mkt_carrier_fl_num',\n",
    "                                          'op_unique_carrier','tail_num','op_carrier_fl_num','origin_airport_id','origin',\n",
    "                                          'origin_city_name','dest_airport_id','dest','dest_city_name','crs_dep_time','crs_arr_time',\n",
    "                                          'dup','crs_elapsed_time','flights','distance'],\n",
    "                        removal_list=['mkt_unique_carrier','branded_code_share','mkt_carrier','op_unique_carrier','op_carrier_fl_num',\n",
    "                                        'tail_num','origin','origin_city_name','dest','dest_city_name','dup','flights'],\n",
    "                         target='arr_delay'):\n",
    "    \"\"\"\n",
    "    This function reduces the features of a DataFrame to only those relevant to the analysis or model trained at hand, including\n",
    "    the target variable. \n",
    "    \n",
    "    Args:\n",
    "        df - Pandas DataFrame \n",
    "        full_features - List of features to be reduced. Defaults to case-specific \"flights_test\" features if no input is given.\n",
    "        removal_list - List of features to be removed. Defaults to case-specific \"flights_test\" features if no input is given.\n",
    "        target - Target variable to be included in final DataFrame. Defaults to case-specific 'arr_delay' if no input is given. \n",
    "    Output:\n",
    "        Processed DataFrame with reduced number of features is returned.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Implement list comprehension to build `training_features` list composed.\n",
    "    training_features = [ x for x in full_features if x not in removal_list]\n",
    "    \n",
    "    # Append target variable column to DataFrame\n",
    "    training_features.append('arr_delay')\n",
    "    \n",
    "    # Redefine and return DataFrame\n",
    "    df = df[training_features]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_month_dummies(df, date_column):\n",
    "    df['month']=df[date_column].dt.month\n",
    "    df = pd.get_dummies(df, columns=['month'])\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
